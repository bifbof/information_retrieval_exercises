{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "packed-yesterday",
   "metadata": {},
   "source": [
    "# K-gram indices\n",
    "\n",
    "This week the exercise focuses on k-gram indices, and two uses for them: (i) wildcard queries (`some*e`) and (ii) spell correction (`smoetime` → `sometime`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "from textutils import tokenize_document\n",
    "from queryparser import parse_query, ast_has_operation, process_ast, Operation, ParseException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-observation",
   "metadata": {},
   "source": [
    "The provided window function returns sliding-n-window subsequences of the input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, n):\n",
    "    for i in range(len(seq) - n + 1):\n",
    "        yield seq[i:i+n]\n",
    "print(list(window([2, 3, 4, 5, 6], 2)))\n",
    "print(list(window(\"astring\", 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map document titles to document ids\n",
    "documents = {}\n",
    "# A running counter for assigning numerical IDs to documents'''\n",
    "docid_counter = 1\n",
    "# The posting lists\n",
    "the_index = {}\n",
    "# K-gram index\n",
    "kgram_index = dict()\n",
    "# The K in k-gram\n",
    "K = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-helping",
   "metadata": {},
   "source": [
    "Note that from this week onwards the posting lists will be a python `set`: this way we can use its built in deduplication, `&` (intersection), `|` (union), and `-` (difference):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_set = {3, 4}\n",
    "example_set.add(6)\n",
    "example_set.add(4)\n",
    "print(example_set)\n",
    "print(example_set & {4, 6, 7})\n",
    "print(example_set | {4, 6, 7})\n",
    "print(example_set - {4, 6, 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-linux",
   "metadata": {},
   "source": [
    "Add documents to the index, and words to the k-gram index. Make sure the posting lists are python `set`s.\n",
    "\n",
    "For the k-gram index you will want to bracket each term in the vocabulary of\n",
    "your standard inverted index with dollar signs, which are used as word\n",
    "boundary markers and are important to process queries where the wildcard is at\n",
    "the beginning or at the end of a term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wipe existing data\n",
    "documents = {}\n",
    "docid_counter = 1\n",
    "the_index = {}\n",
    "kgram_index = dict()\n",
    "\n",
    "for doc in glob.glob('../../shared/corpus/*.txt'):\n",
    "    docid = docid_counter\n",
    "    documents[docid] = doc\n",
    "    docid_counter += 1\n",
    "    print(\"Added document %s with id %d\" % (doc, docid))\n",
    "    for word in tokenize_document(doc):\n",
    "        the_index.setdefault(word, set()).add(docid)\n",
    "\n",
    "for word in the_index.keys():\n",
    "    ### TODO for the assignment: add words to the k-gram index\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-adventure",
   "metadata": {},
   "source": [
    "Here's a test to check the k-gram index is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(kgram_index['$ze'] == {'zeal', 'zeale', 'zealous', 'zeals', 'zeal—', 'zed', 'zenith', 'zephyrs'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-cornell",
   "metadata": {},
   "source": [
    "## Wildcard queries\n",
    "\n",
    "Write a function that takes a wildcard query term (`'some*e'`) and returns all the keys to query in the k-gram index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wildcard_parse(q):\n",
    "    ### TODO for the assignment: parse the wildcard term and return a list of k-grams\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-angle",
   "metadata": {},
   "source": [
    "Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(wildcard_parse('some*e') == ['$so', 'som', 'ome'])\n",
    "assert(wildcard_parse('*where') == ['whe', 'her', 'ere', 're$'])\n",
    "assert(wildcard_parse('some*ere') == ['$so', 'som', 'ome', 'ere', 're$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-evans",
   "metadata": {},
   "source": [
    "Implement querying the k-gram index for matching words, given a certain wildcard query `q`. Here's an high-level description for the implementation:\n",
    "\n",
    "  * parse the wildcard query with `wildcard_parse`;\n",
    "  * check whether any of the returned kgrams are not in the `kgram_index`: if that's the case, there are no matches for this wildcard query, and and empty set should be returned;\n",
    "  * (optionally) compute the number of matches for each kgram and order them from smaller to larger;\n",
    "  * intersect the word matches for each kgram;\n",
    "  * perform post-processing to exclude false positives (we provide some code that converts the wildcard query in a python regex that only matches valid words);\n",
    "  * return the set of matching words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgram_wildcard_query(q):\n",
    "    grams = wildcard_parse(q)\n",
    "    ### TODO for the assignment: execute the wildcard query on the k-gram index\n",
    "    kgram_matches = {}\n",
    "    result = {r for r in kgram_matches if post_filter.match(r) is not None}\n",
    "    print(\"NOTE: wildcard matches for '%s': %s\" % (q, result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-albania",
   "metadata": {},
   "source": [
    "Don't forget to perform post-processing to exclude false positives. Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(kgram_wildcard_query('some*e') == {'someone', 'somewhere', 'sometime'})\n",
    "assert(kgram_wildcard_query('*where') == {'otherwhere', 'everywhere', 'nowhere', 'elsewhere', 'anywhere', 'where', 'somewhere'})\n",
    "assert(kgram_wildcard_query('rend*') == {'rend', 'render', 'renderd', 'rendered', 'renders', 'rendezvous', 'rendred', 'rendring'})\n",
    "len(kgram_wildcard_query('man*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-terrace",
   "metadata": {},
   "source": [
    "We provide a generic implementation of `execute_query`. Note that intersection/union operations are implemented with Python's sets. This implementation will invoke `kgram_wildcard_query` when it encounters a wildcard query during preprocessing. It will replace the wildcard term with a disjunction of the matching words (`some*e` → `someone OR somewhere OR sometime`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary empty implementation of `spellcorrect`: this will be relevant later\n",
    "def spellcorrect(arg):\n",
    "    return None\n",
    "\n",
    "def execute_query(query):\n",
    "    def negate(postings):\n",
    "        return set(documents.keys()) - postings\n",
    "\n",
    "    try:\n",
    "        ast = parse_query(query)\n",
    "    except ParseException as e:\n",
    "        print(\"Failed to parse query '%s'\\n\" % query, e)\n",
    "        return None\n",
    "\n",
    "    flat = process_ast(ast)\n",
    "\n",
    "    def preprocess_query_tree(tree):\n",
    "        if tree.op == 'LOOKUP':\n",
    "            tree.op = 'AND'\n",
    "        new_args = []\n",
    "        for arg in tree.args:\n",
    "            if isinstance(arg, Operation):\n",
    "                new_args.append(preprocess_query_tree(arg))\n",
    "            elif \"*\" in arg:\n",
    "                kgram_matches = kgram_wildcard_query(arg)\n",
    "                if len(kgram_matches) == 0:\n",
    "                    print(\"NOTE: spell-correcting term '%s' because no document contains it\" % arg)\n",
    "                elif arg.startswith('-'):\n",
    "                    not_op = Operation('NOT', [\n",
    "                        Operation('OR', list(kgram_matches)),])\n",
    "                    new_args.append(not_op)\n",
    "                elif tree.op == 'OR':\n",
    "                    new_args.extend(kgram_matches)\n",
    "                else:\n",
    "                    new_args.append(Operation('OR', kgram_matches))\n",
    "            else:\n",
    "                if not arg.startswith('-') and arg not in the_index:\n",
    "                    print(\"NOTE: spell-correcting term '%s' because no document contains it\" % arg)\n",
    "                    res = spellcorrect(arg)\n",
    "                    # NOTE: spellcorrect is the second part of this exercise, and will return None until implemented\n",
    "                    if res != None and res != []:\n",
    "                        print(\"NOTE: spell-corrections with Jaccard_threshold for '%s': %s\" % (arg, res))\n",
    "                        new_args.append(Operation('OR', list(res)))\n",
    "                else:\n",
    "                    new_args.append(arg)\n",
    "        tree.args = new_args\n",
    "\n",
    "    preprocess_query_tree(flat)\n",
    "\n",
    "    def execute_query_tree(tree):\n",
    "        result = set()\n",
    "        if tree.op == 'AND':\n",
    "            result = set(documents.keys())\n",
    "        for arg in tree.args:\n",
    "            if isinstance(arg, Operation):\n",
    "                temp = execute_query_tree(arg)\n",
    "            elif arg.startswith('-'):\n",
    "                temp = negate(the_index[arg[1:]])\n",
    "            else:\n",
    "                temp = the_index[arg]\n",
    "\n",
    "            if tree.op == 'OR':\n",
    "                result = result | temp\n",
    "            elif tree.op == 'AND':\n",
    "                result = result & temp\n",
    "            elif tree.op == 'NOT':\n",
    "                assert(len(tree.args) == 1)\n",
    "                result = negate(temp)\n",
    "        return result\n",
    "\n",
    "    return execute_query_tree(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted to windows lexicographic ordering!\n",
    "assert(execute_query('some*e') == {1, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 19, 21, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44})\n",
    "assert(execute_query('some*e AND Romeo') == {38})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-industry",
   "metadata": {},
   "source": [
    "## Spell-checking with a k-gram index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jaccard_threshold = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-concrete",
   "metadata": {},
   "source": [
    "Implement spell-correction for a word that was not found in the index, using the k-gram index.\n",
    "\n",
    "  * Compute the k-grams from the input word (remember to include the '\\$' characters);\n",
    "  * find the matching words for each k-gram;\n",
    "  * for each candidate word, check the Jaccard coefficent between the input word and the candidate (remember to include the '\\$' characters);\n",
    "  * if it's above (greater or equal to) the provided threshold, add it to the list of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcorrect(word):\n",
    "    word_grams = set(window('$' + word + '$', 3))\n",
    "    ### TODO for the assignment: implement spell-correction\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-blake",
   "metadata": {},
   "source": [
    "Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(spellcorrect('smoetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(spellcorrect('smoetime')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-advocacy",
   "metadata": {},
   "source": [
    "Note that the assertions that follow assume a Jaccard threshold of .25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(set(spellcorrect('smoetime')) == {'betime', 'lifetime', 'sometime', 'pastime', 'bedtime', 'time', 'Betimes', 'mestime', 'ruttime', '“Sometime', 'Sometime', 'betimes', 'Beforetime'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-wages",
   "metadata": {},
   "source": [
    "You can try your code as part of the query processor, which already calls `spellcorrect` whenever a (non-negated) term cannot be found in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted to windows lexicographic ordering!\n",
    "assert(execute_query('smoetime AND Romeo') == {38})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
