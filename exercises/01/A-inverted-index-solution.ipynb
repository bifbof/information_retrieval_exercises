{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sophisticated-viewer",
   "metadata": {},
   "source": [
    "Implementing a simple inverted index\n",
    "====================================\n",
    "\n",
    "In this exercise you will implement a simple inverted index in python.\n",
    "\n",
    "We provide a boolean query parser for you. You can use the parser as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d50b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coral-yeast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AST({'fst': AST({'fst': AST({'fst': 'Caesar', 'op': None, 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@17, rule='notexpr', pos=0, endpos=6, line=0, endline=0)}), 'op': 'AND', 'lst': AST({'fst': 'Brutus', 'op': None, 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@17, rule='notexpr', pos=11, endpos=17, line=0, endline=1)}), 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@17, rule='andexpr', pos=0, endpos=17, line=0, endline=1)}), 'lst': None, 'op': None, 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@17, rule='expr', pos=0, endpos=17, line=0, endline=1)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from queryparser import parse_query\n",
    "parse_query('Caesar AND Brutus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-failure",
   "metadata": {},
   "source": [
    "Note that the result of `parse_query` is an abstract syntax tree (AST).  We\n",
    "provide another method `process_ast`, which will traverse the AST and produce\n",
    "a flattened version for some queries.  The parser can deal with any valid\n",
    "boolean query which uses the operators `AND`, `OR`, and `NOT`. However your\n",
    "solution will not have to be able to handle all the possible queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cosmetic-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AND: args=['Caesar', 'Brutus']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from queryparser import parse_query, process_ast\n",
    "process_ast(parse_query('Caesar AND Brutus'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-coverage",
   "metadata": {},
   "source": [
    "To handle errors in the query parser, you can catch `ParseException`.  For\n",
    "example, the query `Clown AND OR Circus` is not a well-formed boolean query.\n",
    "To not have your code crash with an unhandled exception you can do something\n",
    "like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "biblical-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse query:\n",
      " (1:13) \"OR\" is a reserved word :\n",
      "Clown AND OR Circus\n",
      "            ^\n",
      "word\n",
      "primaryexpr\n",
      "notexpr\n",
      "andexpr\n",
      "expr\n",
      "start\n"
     ]
    }
   ],
   "source": [
    "from queryparser import ParseException\n",
    "try:\n",
    "    ast = parse_query('Clown AND OR Circus')\n",
    "except ParseException as e:\n",
    "    print(\"Failed to parse query:\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-source",
   "metadata": {},
   "source": [
    "For the purposes of this exercise we provide you with the collected works of\n",
    "Shakespeare as retrieved from\n",
    "[gutenberg.org](http://www.gutenberg.org/files/100/100-0.txt) and split up\n",
    "into individual text files which you can find in `shared/corpus` in the root\n",
    "directory of your Jupyter account (which is your home directory on that\n",
    "machine).\n",
    "\n",
    "In a future exercise, we will ask you to implement an algorithm for splitting\n",
    "up such a text file into smaller documents yourselves, but for this week, we\n",
    "have done the preprocessing for you.\n",
    "\n",
    "To iterate over all the text files, for example to add them to your inverted\n",
    "index, you can use python's `glob` library which allows you to list files\n",
    "using regular Unix shell [glob syntax](https://en.wikipedia.org/wiki/Glob_(programming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../shared/corpus\\alls_well_that_ends_well.txt\n",
      "../../shared/corpus\\as_you_like_it.txt\n",
      "../../shared/corpus\\a_lovers_complaint.txt\n",
      "../../shared/corpus\\a_midsummer_nights_dream.txt\n",
      "../../shared/corpus\\cymbeline.txt\n",
      "../../shared/corpus\\king_henry_the_eighth.txt\n",
      "../../shared/corpus\\king_john.txt\n",
      "../../shared/corpus\\king_richard_the_second.txt\n",
      "../../shared/corpus\\king_richard_the_third.txt\n",
      "../../shared/corpus\\loves_labours_lost.txt\n",
      "../../shared/corpus\\measure_for_measure.txt\n",
      "../../shared/corpus\\much_ado_about_nothing.txt\n",
      "../../shared/corpus\\pericles_prince_of_tyre.txt\n",
      "../../shared/corpus\\the_comedy_of_errors.txt\n",
      "../../shared/corpus\\the_first_part_of_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_first_part_of_king_henry_the_fourth.txt\n",
      "../../shared/corpus\\the_history_of_troilus_and_cressida.txt\n",
      "../../shared/corpus\\the_life_of_king_henry_the_fifth.txt\n",
      "../../shared/corpus\\the_life_of_timon_of_athens.txt\n",
      "../../shared/corpus\\the_merchant_of_venice.txt\n",
      "../../shared/corpus\\the_merry_wives_of_windsor.txt\n",
      "../../shared/corpus\\the_passionate_pilgrim.txt\n",
      "../../shared/corpus\\the_phoenix_and_the_turtle.txt\n",
      "../../shared/corpus\\the_rape_of_lucrece.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_fourth.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_sonnets.txt\n",
      "../../shared/corpus\\the_taming_of_the_shrew.txt\n",
      "../../shared/corpus\\the_tempest.txt\n",
      "../../shared/corpus\\the_third_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_tragedy_of_antony_and_cleopatra.txt\n",
      "../../shared/corpus\\the_tragedy_of_coriolanus.txt\n",
      "../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "../../shared/corpus\\the_tragedy_of_king_lear.txt\n",
      "../../shared/corpus\\the_tragedy_of_macbeth.txt\n",
      "../../shared/corpus\\the_tragedy_of_othello_moor_of_venice.txt\n",
      "../../shared/corpus\\the_tragedy_of_romeo_and_juliet.txt\n",
      "../../shared/corpus\\the_tragedy_of_titus_andronicus.txt\n",
      "../../shared/corpus\\the_two_gentlemen_of_verona.txt\n",
      "../../shared/corpus\\the_two_noble_kinsmen.txt\n",
      "../../shared/corpus\\the_winters_tale.txt\n",
      "../../shared/corpus\\twelfth_night_or_what_you_will.txt\n",
      "../../shared/corpus\\venus_and_adonis.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for file in glob.glob(\"../../shared/corpus/*.txt\"):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-helena",
   "metadata": {},
   "source": [
    "Now that we have a way to parse a boolean query, and a corpus of documents,\n",
    "what is left to do is to implement a simple inverted index.  For this exercise\n",
    "you can assume that the dictionary, and the postings fit into main memory.\n",
    "\n",
    "We also provide you with a very simple method which handles both the\n",
    "tokenizing of a document and preprocessing of the resulting tokens.  This\n",
    "method will not do much linguistic preprocessing but rather just strips each\n",
    "token of special characters such as quotes, punctuation marks, etc.\n",
    "\n",
    "We will discuss linguistic preprocessing in more details in future exercises.\n",
    "\n",
    "Below is a very simple example of how to use the `tokenize_document` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "metallic-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE\n",
      "PHOENIX\n",
      "AND\n",
      "THE\n",
      "TURTLE\n",
      "William\n",
      "Shakespeare\n",
      "Let\n",
      "bird\n",
      "loudest\n",
      "lay\n",
      "On\n",
      "sole\n",
      "Arabian\n",
      "tree\n",
      "Herald\n",
      "sad\n",
      "trumpet\n",
      "be\n",
      "To\n",
      "whose\n",
      "sound\n",
      "chaste\n",
      "wings\n",
      "obey\n",
      "But\n",
      "thou\n",
      "shrieking\n",
      "harbinger\n",
      "Foul\n",
      "precurrer\n",
      "fiend\n",
      "Augur\n",
      "fever’s\n",
      "end\n",
      "To\n",
      "this\n",
      "troop\n",
      "come\n",
      "thou\n",
      "not\n",
      "near\n",
      "From\n",
      "this\n",
      "session\n",
      "interdict\n",
      "Every\n",
      "fowl\n",
      "tyrant\n",
      "wing\n",
      "Save\n",
      "eagle\n",
      "feather’d\n",
      "king\n",
      "Keep\n",
      "obsequy\n",
      "so\n",
      "strict\n",
      "Let\n",
      "priest\n",
      "surplice\n",
      "white\n",
      "That\n",
      "defunctive\n",
      "music\n",
      "can\n",
      "Be\n",
      "deathdivining\n",
      "swan\n",
      "Lest\n",
      "requiem\n",
      "lack\n",
      "his\n",
      "right\n",
      "And\n",
      "thou\n",
      "trebledated\n",
      "crow\n",
      "That\n",
      "thy\n",
      "sable\n",
      "gender\n",
      "mak’st\n",
      "With\n",
      "breath\n",
      "thou\n",
      "giv’st\n",
      "tak’st\n",
      "’Mongst\n",
      "our\n",
      "mourners\n",
      "shalt\n",
      "thou\n",
      "go\n",
      "Here\n",
      "anthem\n",
      "doth\n",
      "commence\n",
      "Love\n",
      "constancy\n",
      "dead\n",
      "Phoenix\n",
      "turtle\n",
      "fled\n",
      "In\n",
      "mutual\n",
      "flame\n",
      "hence\n",
      "So\n",
      "they\n",
      "lov’d\n",
      "love\n",
      "twain\n",
      "Had\n",
      "essence\n",
      "but\n",
      "one\n",
      "Two\n",
      "distincts\n",
      "division\n",
      "none\n",
      "Number\n",
      "there\n",
      "love\n",
      "slain\n",
      "Hearts\n",
      "remote\n",
      "yet\n",
      "not\n",
      "asunder\n",
      "Distance\n",
      "no\n",
      "space\n",
      "seen\n",
      "’Twixt\n",
      "this\n",
      "turtle\n",
      "his\n",
      "queen\n",
      "But\n",
      "them\n",
      "wonder\n",
      "So\n",
      "between\n",
      "them\n",
      "love\n",
      "did\n",
      "shine\n",
      "That\n",
      "turtle\n",
      "saw\n",
      "his\n",
      "right\n",
      "Flaming\n",
      "phoenix’\n",
      "sight\n",
      "Either\n",
      "other’s\n",
      "mine\n",
      "Property\n",
      "thus\n",
      "appalled\n",
      "That\n",
      "self\n",
      "not\n",
      "same\n",
      "Single\n",
      "nature’s\n",
      "double\n",
      "name\n",
      "Neither\n",
      "two\n",
      "nor\n",
      "one\n",
      "called\n",
      "Reason\n",
      "itself\n",
      "confounded\n",
      "Saw\n",
      "division\n",
      "grow\n",
      "together\n",
      "To\n",
      "themselves\n",
      "yet\n",
      "either\n",
      "neither\n",
      "Simple\n",
      "so\n",
      "well\n",
      "compounded\n",
      "That\n",
      "cried\n",
      "How\n",
      "true\n",
      "twain\n",
      "Seemeth\n",
      "this\n",
      "concordant\n",
      "one\n",
      "Love\n",
      "hath\n",
      "reason\n",
      "reason\n",
      "none\n",
      "If\n",
      "what\n",
      "parts\n",
      "can\n",
      "so\n",
      "remain\n",
      "Whereupon\n",
      "made\n",
      "this\n",
      "threne\n",
      "To\n",
      "phoenix\n",
      "dove\n",
      "Cosupremes\n",
      "stars\n",
      "love\n",
      "As\n",
      "chorus\n",
      "their\n",
      "tragic\n",
      "scene\n",
      "THRENOS\n",
      "Beauty\n",
      "truth\n",
      "rarity\n",
      "Grace\n",
      "all\n",
      "simplicity\n",
      "Here\n",
      "enclos’d\n",
      "cinders\n",
      "lie\n",
      "Death\n",
      "now\n",
      "phoenix’\n",
      "nest\n",
      "And\n",
      "turtle’s\n",
      "loyal\n",
      "breast\n",
      "To\n",
      "eternity\n",
      "doth\n",
      "rest\n",
      "Leaving\n",
      "no\n",
      "posterity—\n",
      "’Twas\n",
      "not\n",
      "their\n",
      "infirmity\n",
      "It\n",
      "married\n",
      "chastity\n",
      "Truth\n",
      "may\n",
      "seem\n",
      "but\n",
      "cannot\n",
      "be\n",
      "Beauty\n",
      "brag\n",
      "but\n",
      "’tis\n",
      "not\n",
      "she\n",
      "Truth\n",
      "beauty\n",
      "buried\n",
      "be\n",
      "To\n",
      "this\n",
      "urn\n",
      "let\n",
      "those\n",
      "repair\n",
      "That\n",
      "either\n",
      "true\n",
      "or\n",
      "fair\n",
      "For\n",
      "these\n",
      "dead\n",
      "birds\n",
      "sigh\n",
      "prayer\n"
     ]
    }
   ],
   "source": [
    "from textutils import tokenize_document\n",
    "for token in tokenize_document('../../shared/corpus/the_phoenix_and_the_turtle.txt'):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-jewel",
   "metadata": {},
   "source": [
    "Now all that is left to do is to implement some code which will create an\n",
    "inverted index.  We give you a very simple skeleton which outlines the\n",
    "implementation work that you will have to do.\n",
    "\n",
    "In the index we want to refer to documents by a document ID.\n",
    "We define variables `documents` which we will assume to be the datastructure\n",
    "mapping document IDs to documents and `the_index` which will be the variable\n",
    "holding the inverted index.\n",
    "\n",
    "Note that while we currently initialize `the_index` to `None`, you will have\n",
    "to choose a data structure to represent the inverted index, and initialize the\n",
    "variable accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liquid-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = dict()\n",
    "the_index = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-somerset",
   "metadata": {},
   "source": [
    "The easiest way to do this for now, is to simply have a counter which we\n",
    "increment every time we add a document to the index.  In order to be able to\n",
    "produce human-readable results you will need to also keep track of which\n",
    "document ID refers to which document.  The function we provide to print\n",
    "results expects that `documents` is a `dict` mapping document IDs to document\n",
    "file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "absolute-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentid_counter = 1\n",
    "def add_document(path):\n",
    "    '''\n",
    "    Add a document to the inverted index. Return the document's document ID.\n",
    "    Remember the mapping from document ID to document in the `documents`\n",
    "    data structure.\n",
    "    '''\n",
    "    # make sure that we access the global variables we have defined\n",
    "    global the_index, documents, documentid_counter\n",
    "    print(\"Adding '%s' to index\" % path)\n",
    "    docid = documentid_counter\n",
    "    documents[docid] = path\n",
    "    documentid_counter += 1\n",
    "    for word in tokenize_document(path):\n",
    "        if word in the_index.keys() and the_index[word][-1] == docid:\n",
    "            continue\n",
    "        the_index.setdefault(word, []).append(docid)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-track",
   "metadata": {},
   "source": [
    "Assuming you have implemented `add_document` correctly you should be able to\n",
    "create an inverted index as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "progressive-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding '../../shared/corpus\\alls_well_that_ends_well.txt' to index\n",
      "Adding '../../shared/corpus\\as_you_like_it.txt' to index\n",
      "Adding '../../shared/corpus\\a_lovers_complaint.txt' to index\n",
      "Adding '../../shared/corpus\\a_midsummer_nights_dream.txt' to index\n",
      "Adding '../../shared/corpus\\cymbeline.txt' to index\n",
      "Adding '../../shared/corpus\\king_henry_the_eighth.txt' to index\n",
      "Adding '../../shared/corpus\\king_john.txt' to index\n",
      "Adding '../../shared/corpus\\king_richard_the_second.txt' to index\n",
      "Adding '../../shared/corpus\\king_richard_the_third.txt' to index\n",
      "Adding '../../shared/corpus\\loves_labours_lost.txt' to index\n",
      "Adding '../../shared/corpus\\measure_for_measure.txt' to index\n",
      "Adding '../../shared/corpus\\much_ado_about_nothing.txt' to index\n",
      "Adding '../../shared/corpus\\pericles_prince_of_tyre.txt' to index\n",
      "Adding '../../shared/corpus\\the_comedy_of_errors.txt' to index\n",
      "Adding '../../shared/corpus\\the_first_part_of_henry_the_sixth.txt' to index\n",
      "Adding '../../shared/corpus\\the_first_part_of_king_henry_the_fourth.txt' to index\n",
      "Adding '../../shared/corpus\\the_history_of_troilus_and_cressida.txt' to index\n",
      "Adding '../../shared/corpus\\the_life_of_king_henry_the_fifth.txt' to index\n",
      "Adding '../../shared/corpus\\the_life_of_timon_of_athens.txt' to index\n",
      "Adding '../../shared/corpus\\the_merchant_of_venice.txt' to index\n",
      "Adding '../../shared/corpus\\the_merry_wives_of_windsor.txt' to index\n",
      "Adding '../../shared/corpus\\the_passionate_pilgrim.txt' to index\n",
      "Adding '../../shared/corpus\\the_phoenix_and_the_turtle.txt' to index\n",
      "Adding '../../shared/corpus\\the_rape_of_lucrece.txt' to index\n",
      "Adding '../../shared/corpus\\the_second_part_of_king_henry_the_fourth.txt' to index\n",
      "Adding '../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt' to index\n",
      "Adding '../../shared/corpus\\the_sonnets.txt' to index\n",
      "Adding '../../shared/corpus\\the_taming_of_the_shrew.txt' to index\n",
      "Adding '../../shared/corpus\\the_tempest.txt' to index\n",
      "Adding '../../shared/corpus\\the_third_part_of_king_henry_the_sixth.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_antony_and_cleopatra.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_coriolanus.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_julius_caesar.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_king_lear.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_macbeth.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_othello_moor_of_venice.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_romeo_and_juliet.txt' to index\n",
      "Adding '../../shared/corpus\\the_tragedy_of_titus_andronicus.txt' to index\n",
      "Adding '../../shared/corpus\\the_two_gentlemen_of_verona.txt' to index\n",
      "Adding '../../shared/corpus\\the_two_noble_kinsmen.txt' to index\n",
      "Adding '../../shared/corpus\\the_winters_tale.txt' to index\n",
      "Adding '../../shared/corpus\\twelfth_night_or_what_you_will.txt' to index\n",
      "Adding '../../shared/corpus\\venus_and_adonis.txt' to index\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for file in glob.glob('../../shared/corpus/*.txt'):\n",
    "    add_document(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-drama",
   "metadata": {},
   "source": [
    "Now you need to implement a method to process boolean queries.  For this\n",
    "exercise it is enough if your query processing can handle simple boolean\n",
    "query with at most one operation.  Below is a selection of queries your\n",
    "implementation should be able to handle.\n",
    "\n",
    "So you do not have to walk the AST you can use the method `process_ast` which\n",
    "was mentioned earlier to transform the AST into a flattened representation.\n",
    "Additionally we provide a method `operation_is_complex`, which will return\n",
    "`True` if the query is more complex than what we reasonably expect you to\n",
    "handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continued-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AST representation: AST({'fst': AST({'fst': AST({'fst': 'Brutus', 'op': None, 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@20, rule='notexpr', pos=0, endpos=6, line=0, endline=0)}), 'op': 'AND', 'lst': AST({'fst': 'Calpurnia', 'op': None, 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@20, rule='notexpr', pos=11, endpos=20, line=0, endline=1)}), 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@20, rule='andexpr', pos=0, endpos=20, line=0, endline=1)}), 'lst': None, 'op': None, 'parseinfo': ParseInfo(buffer=BooleanQueryBuffer@20, rule='expr', pos=0, endpos=20, line=0, endline=1)})\n",
      "Flattened representation: AND: args=['Brutus', 'Calpurnia']\n",
      "AND\n",
      "['Brutus', 'Calpurnia']\n"
     ]
    }
   ],
   "source": [
    "from queryparser import process_ast\n",
    "ast = parse_query('Brutus AND Calpurnia')\n",
    "print(\"AST representation:\", ast)\n",
    "flat = process_ast(ast)\n",
    "print(\"Flattened representation:\", flat)\n",
    "print(flat.op)\n",
    "print(flat.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-highland",
   "metadata": {},
   "source": [
    "As you can see, it is easier to extract the operation and operands from the\n",
    "flat representation.  The flattened representation is composed from\n",
    "`Operation` objects, and strings.\n",
    "An `Operation` object is a representation of a boolean query operation.  The\n",
    "`op` field represents the operation type which should be one of `AND`, `OR`,\n",
    "`NOT`, or `LOOKUP`.\n",
    "The `args` field is a list of one or more arguments for the operation.  `NOT`\n",
    "and `LOOKUP` operations are expected to have a argument list of length one.\n",
    "`AND`, and `OR` can have arbitrarily long argument lists, but the argument\n",
    "list for such an operation should contain at least two elements.\n",
    "For `AND` and `OR`, we represent operands of the form 'NOT <term>' as the\n",
    "string '-<term>' to allow more efficient execution of queries of the form 'a\n",
    "AND NOT b' and 'a OR NOT b'.\n",
    "\n",
    "Before directly diving into the full query processing code, you will have to\n",
    "implement methods that compute the intersection and union of two postings\n",
    "lists.  We give you method declarations for these operations, but if you need\n",
    "to change the method arguments feel free to do so.\n",
    "\n",
    "While we do not give hard requirements on the method arguments for either\n",
    "operation, you should probably consider making it a requirement that the\n",
    "postings lists which you pass to `intersect` and `union` are sorted, as that\n",
    "will make implementing the functionality significantly easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "automated-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(p1, p2):\n",
    "    '''\n",
    "    Method to compute the intersection of two postings lists.  Takes two\n",
    "    postings lists as arguments and returns the intersection.\n",
    "    '''\n",
    "    answer = []\n",
    "    while p1 != [] and p2 != []:\n",
    "        if p1[0] == p2[0]:\n",
    "            answer.append(p1[0])\n",
    "            p1 = p1[1:]\n",
    "            p2 = p2[1:]\n",
    "        elif p1[0] < p2[0]:\n",
    "            p1 = p1[1:]\n",
    "        else:\n",
    "            p2 = p2[1:]\n",
    "    return answer\n",
    "\n",
    "def union(p1, p2):\n",
    "    '''\n",
    "    Method to compute the union of two postings lists.  Takes two\n",
    "    postings lists as arguments and returns the union.\n",
    "    '''\n",
    "    answer = []\n",
    "    while p1 != [] and p2 != []:\n",
    "        if p1[0] == p2[0]:\n",
    "            answer.append(p1[0])\n",
    "            p1 = p1[1:]\n",
    "            p2 = p2[1:]\n",
    "        elif p1[0] < p2[0]:\n",
    "            answer.append(p1[0])\n",
    "            p1 = p1[1:]\n",
    "        else:\n",
    "            answer.append(p2[0])\n",
    "            p2 = p2[1:]\n",
    "    if p1 != []:\n",
    "        answer.extend(p1)\n",
    "    else:\n",
    "        answer.extend(p2)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-mauritius",
   "metadata": {},
   "source": [
    "Below there are a few example calls to `intersect` and `union` which you can\n",
    "use to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "romantic-forty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n",
      "[]\n",
      "[1, 6]\n",
      "[]\n",
      "[1, 2, 3, 4]\n",
      "[1, 2, 4]\n",
      "[1, 2, 4, 5, 6]\n",
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(intersect([1,2,3,6], [1,3,4])) # should produce [1,3]\n",
    "print(intersect([1,6], [3,4])) # should produce []\n",
    "print(intersect([1,2,6], [1,6])) # should produce [1,6]\n",
    "print(intersect([], [1,3])) # should produce []\n",
    "\n",
    "print(union([1,2], [3,4])) # should produce [1,2,3,4]\n",
    "print(union([1,2], [1,2,4])) # should produce [1,2,4]\n",
    "print(union([1,2,6], [2,4,5])) # should produce [1,2,4,5,6]\n",
    "print(union([], [1,3])) # should produce [1,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-robertson",
   "metadata": {},
   "source": [
    "Now you should be fairly well-equipped to implement a boolean query processor.\n",
    "Feel free to split your implementation into multiple methods if you find that\n",
    "`execute_query` is getting too big for your taste.\n",
    "\n",
    "Note that we expect you to implement intersections and unions of more than two\n",
    "terms in the way discussed in the lecture and the book.\n",
    "\n",
    "Queries that are conjunctions where all terms are negated (i.e.\n",
    "`NOT Brutus AND NOT Calpurnia`) and queries that are disjunction where\n",
    "at least one term is negated (i.e. `Brutus OR NOT Calpurnia OR Hamlet`)\n",
    "are often not implemented in real-world, large-scale, general purpose systems.\n",
    "We do not expect you to implement them either, your code can just return `None`\n",
    "in these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compound-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queryparser import Operation\n",
    "\n",
    "def negate(term):\n",
    "    '''\n",
    "    Negate postings list for `term`.  This is not feasible in a real-world\n",
    "    system, but we utilize this for the fallback execution which is fairly\n",
    "    naive.\n",
    "    '''\n",
    "    if term in the_index.keys():\n",
    "        return sorted(set(documents.keys()) - set(the_index[term]))\n",
    "    else:\n",
    "        return list(documents.keys())\n",
    "\n",
    "def execute_query_tree(flat):\n",
    "    '''\n",
    "    Fallback query execution for complex queries, we just recursively evaluate\n",
    "    subtrees.\n",
    "    '''\n",
    "    result = set()\n",
    "    if flat.op == 'AND':\n",
    "        result = set(documents.keys())\n",
    "    for arg in flat.args:\n",
    "        # execute subtree etc\n",
    "        if isinstance(arg, Operation):\n",
    "            temp = execute_query_tree(arg)\n",
    "        elif arg.startswith('-'):\n",
    "            temp = negate(arg[1:])\n",
    "        elif arg not in the_index.keys():\n",
    "            print(\"NOTE: dropping term '%s' because no document contains it\" % arg)\n",
    "        else:\n",
    "            temp = the_index[arg]\n",
    "\n",
    "        if flat.op == 'OR':\n",
    "            result = result | set(temp)\n",
    "        elif flat.op == 'AND':\n",
    "            result = result & set(temp)\n",
    "        elif flat.op == 'NOT':\n",
    "            assert(len(flat.args) == 1)\n",
    "            result = set(documents.keys()) - set(temp)\n",
    "\n",
    "    return sorted(result)\n",
    "\n",
    "def intersect_list(terms):\n",
    "    '''\n",
    "    Intersect posting lists for a list of terms, according to pseudo-code\n",
    "    in Introduction to Information Retrieval, Figure 1.7\n",
    "    '''\n",
    "    postings = [ the_index[t] if not t.startswith('-') else\n",
    "                 negate(t[1:]) for t in terms ]\n",
    "    # calculate word frequencies and sort term,freq pairs in ascending\n",
    "    # order by frequency\n",
    "    freqs = sorted([ (t, len(p)) for t,p in zip(terms, postings) ], key=lambda x: x[1] )\n",
    "    terms, _ = map(list,zip(*freqs))\n",
    "    if terms[0].startswith('-'):\n",
    "        result = negate(terms[0][1:])\n",
    "    else:\n",
    "        result = the_index[terms[0]]\n",
    "    terms = terms[1:]\n",
    "    while terms != [] and result != []:\n",
    "        if terms[0].startswith('-'):\n",
    "            ps = negate(terms[0][1:])\n",
    "        else:\n",
    "            ps = the_index[terms[0]]\n",
    "        result = intersect(result, ps)\n",
    "        terms = terms[1:]\n",
    "    return result\n",
    "\n",
    "def execute_query(query):\n",
    "    '''\n",
    "    Execute a boolean query on the inverted index. This method should return a\n",
    "    list of document ids which satisfy the query. The list does not need to be\n",
    "    in a particular order.\n",
    "    '''\n",
    "    try:\n",
    "        ast = parse_query(query)\n",
    "    except ParseException as e:\n",
    "        print(\"Failed to parse query '%s':\\n\" % query, e)\n",
    "\n",
    "    # We preprocess the AST to flatten commutative operations, such as\n",
    "    # sequences of ANDs. We also transform 'NOT <term>' arguments into\n",
    "    # '-<term>' to allow smarter processing of AND NOT and OR NOT.\n",
    "    flat = process_ast(ast)\n",
    "\n",
    "    # Feel free to remove this print() if you don't find it helpful.\n",
    "    print(\"Flat query repr:\", flat)\n",
    "\n",
    "    args = []\n",
    "    # go through arguments and fall back on recursive evaluation if we\n",
    "    # could not completely flatten the query\n",
    "    for arg in flat.args:\n",
    "        if isinstance(arg, Operation):\n",
    "            # as soon as we find a argument to the top-level operation\n",
    "            # which is not just a term, we fall back on the tree query\n",
    "            # execution strategy.\n",
    "            return execute_query_tree(flat)\n",
    "        else:\n",
    "            args.append(arg)\n",
    "\n",
    "    if flat.op == 'OR':\n",
    "        # For demonstration purposes, utilize python's set() datatype \n",
    "        # to implement OR\n",
    "        results = set()\n",
    "        for arg in args:\n",
    "            if arg.startswith('-'):\n",
    "                print(\"OR NOT not handled (query: '%s'\" % query)\n",
    "                return None\n",
    "            else:\n",
    "                results = results | set(the_index[arg])\n",
    "        return sorted(results)\n",
    "\n",
    "    elif flat.op == 'AND':\n",
    "        return intersect_list(args)\n",
    "\n",
    "    elif flat.op == 'LOOKUP':\n",
    "        assert(len(args) == 1)\n",
    "        if args[0] not in the_index.keys():\n",
    "            # single term query for term not in vocabulary, return empty list\n",
    "            # of document IDs\n",
    "            return []\n",
    "        else:\n",
    "            # in this case the query was a single term\n",
    "            return the_index[args[0]]\n",
    "    else:\n",
    "        print(\"Cannot handle query '%s', aborting...\" % query)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-infection",
   "metadata": {},
   "source": [
    "If you can process all the queries given below, you have made a good start on\n",
    "building an inverted index and boolean query processor.\n",
    "A good way to improve your query processing is to directly handle `AND NOT`.\n",
    "You can either try to extend the `intersect` method which you implemented\n",
    "previously, or you can implement `AND NOT` in a separate method.\n",
    "\n",
    "In order to get human readable output, the following function translates\n",
    "document IDs back to file names, assuming you've correctly populated the\n",
    "`documents` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "senior-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(docs):\n",
    "    if not docs:\n",
    "        print(\"No documents found\")\n",
    "        print()\n",
    "        return\n",
    "    # If we got some results, print them\n",
    "    for doc in docs:\n",
    "        print(documents[doc])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "robust-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat query repr: LOOKUP: args=['Caesar']\n",
      "../../shared/corpus\\alls_well_that_ends_well.txt\n",
      "../../shared/corpus\\cymbeline.txt\n",
      "../../shared/corpus\\king_richard_the_third.txt\n",
      "../../shared/corpus\\measure_for_measure.txt\n",
      "../../shared/corpus\\the_first_part_of_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_life_of_king_henry_the_fifth.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_third_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_tragedy_of_antony_and_cleopatra.txt\n",
      "../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "../../shared/corpus\\the_tragedy_of_macbeth.txt\n",
      "../../shared/corpus\\the_tragedy_of_othello_moor_of_venice.txt\n",
      "\n",
      "Flat query repr: LOOKUP: args=['hello']\n",
      "No documents found\n",
      "\n",
      "Flat query repr: AND: args=['Brutus', 'Calpurnia']\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "\n",
      "Flat query repr: OR: args=['Brutus', 'Hamlet']\n",
      "../../shared/corpus\\the_life_of_king_henry_the_fifth.txt\n",
      "../../shared/corpus\\the_merchant_of_venice.txt\n",
      "../../shared/corpus\\the_rape_of_lucrece.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_tragedy_of_antony_and_cleopatra.txt\n",
      "../../shared/corpus\\the_tragedy_of_coriolanus.txt\n",
      "../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "../../shared/corpus\\the_tragedy_of_titus_andronicus.txt\n",
      "\n",
      "Flat query repr: AND: args=['Brutus', '-Calpurnia']\n",
      "../../shared/corpus\\the_life_of_king_henry_the_fifth.txt\n",
      "../../shared/corpus\\the_merchant_of_venice.txt\n",
      "../../shared/corpus\\the_rape_of_lucrece.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_tragedy_of_antony_and_cleopatra.txt\n",
      "../../shared/corpus\\the_tragedy_of_coriolanus.txt\n",
      "../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt\n",
      "../../shared/corpus\\the_tragedy_of_titus_andronicus.txt\n",
      "\n",
      "Flat query repr: AND: args=['Caesar', 'Brutus', 'Calpurnia']\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "\n",
      "Flat query repr: AND: args=['Caesar', 'Brutus', '-Calpurnia']\n",
      "../../shared/corpus\\the_life_of_king_henry_the_fifth.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_tragedy_of_antony_and_cleopatra.txt\n",
      "../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_result(execute_query('Caesar'))\n",
    "print_result(execute_query('hello'))\n",
    "print_result(execute_query('Brutus AND Calpurnia'))\n",
    "print_result(execute_query('Brutus OR Hamlet'))\n",
    "print_result(execute_query('Brutus AND NOT Calpurnia'))\n",
    "print_result(execute_query('Caesar AND Brutus AND Calpurnia'))\n",
    "print_result(execute_query('Caesar AND Brutus AND NOT Calpurnia'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-differential",
   "metadata": {},
   "source": [
    "If you wish, you can try to improve your query processor to handle more\n",
    "complex queries, such as the examples below.  This part is optional.\n",
    "\n",
    "Note that the query parser gives `NOT` precedence over `AND`, and `AND`\n",
    "precedence over `OR` in the absence of parentheses in queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "russian-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat query repr: AND: args=[OR: args=['Caesar', 'Brutus'], 'Calpurnia']\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "\n",
      "Flat query repr: AND: args=[OR: args=['Caesar', 'Brutus'], OR: args=['Calpurnia', 'clown']]\n",
      "../../shared/corpus\\alls_well_that_ends_well.txt\n",
      "../../shared/corpus\\measure_for_measure.txt\n",
      "../../shared/corpus\\the_merchant_of_venice.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "\n",
      "Flat query repr: OR: args=[AND: args=['Brutus', 'Calpurnia'], AND: args=['Romeo', 'Juliet']]\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "../../shared/corpus\\the_tragedy_of_romeo_and_juliet.txt\n",
      "\n",
      "Flat query repr: OR: args=['Caesar', AND: args=['Brutus', 'Calpurnia']]\n",
      "../../shared/corpus\\alls_well_that_ends_well.txt\n",
      "../../shared/corpus\\cymbeline.txt\n",
      "../../shared/corpus\\king_richard_the_third.txt\n",
      "../../shared/corpus\\measure_for_measure.txt\n",
      "../../shared/corpus\\the_first_part_of_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_life_of_king_henry_the_fifth.txt\n",
      "../../shared/corpus\\the_second_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_third_part_of_king_henry_the_sixth.txt\n",
      "../../shared/corpus\\the_tragedy_of_antony_and_cleopatra.txt\n",
      "../../shared/corpus\\the_tragedy_of_hamlet_prince_of_denmark.txt\n",
      "../../shared/corpus\\the_tragedy_of_julius_caesar.txt\n",
      "../../shared/corpus\\the_tragedy_of_macbeth.txt\n",
      "../../shared/corpus\\the_tragedy_of_othello_moor_of_venice.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_result(execute_query('(Caesar OR Brutus) AND Calpurnia'))\n",
    "print_result(execute_query('(Caesar OR Brutus) AND (Calpurnia OR clown)'))\n",
    "print_result(execute_query('(Brutus AND Calpurnia) OR (Romeo AND Juliet)'))\n",
    "print_result(execute_query('Caesar OR Brutus AND Calpurnia'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-mapping",
   "metadata": {},
   "source": [
    "If everything so far was a walk in the park for you, you can even try to\n",
    "implement a method which converts any query into conjunctive normal form\n",
    "(CNF).  Note, however, that converting a boolean formula to CNF is NP hard,\n",
    "and as such we do not require you to do this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
